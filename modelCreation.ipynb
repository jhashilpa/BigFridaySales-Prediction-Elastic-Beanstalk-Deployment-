{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "modelCreation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grudvG5ZXkT4"
      },
      "source": [
        "## Import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtpSsR0XkT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc974cf3-f608-47d0-ee6e-9fa641b6553d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Lasso not completly necessary!! We will see this\n",
        "from sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LinearRegression\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import pickle\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
        "# create a dot_file which stores the tree structure-NOt running in my system\n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcHz2R9aXkUA"
      },
      "source": [
        "## Define all the helper classes and function. \n",
        "#### The accuracy metrics of each model type is stored and then compared with each other to find the optimal Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjNLwJNNpt7x"
      },
      "source": [
        "#Defining class for each Model Type \n",
        "\n",
        "#container to fit the Regression  Model\n",
        "class MultipleRegression():\n",
        "    def __init__(self):\n",
        "        self.metrics={}\n",
        "        self.multiplereg=LinearRegression()\n",
        "    def createRegModel(self):\n",
        "        self.multiplereg.fit(X_train,Y_train)\n",
        "        tScore=self.multiplereg.score(X_train,Y_train)\n",
        "        vScore=self.multiplereg.score(X_valid,Y_valid)\n",
        "        print(\"Training data Score is\",tScore)\n",
        "        print(\"Validation data Score is\",vScore)\n",
        "        pred=self.multiplereg.predict(X_valid) #predicting values of y for all the xtest rows\n",
        "        mse=mean_squared_error(Y_valid,pred)\n",
        "        rmse=round(mse**0.5,2)\n",
        "        print(\"RMSE in case of Multiple regression Model:\",rmse)\n",
        "        print(\"MSE in case of Multiple regression Model:\",mse)\n",
        "        self.metrics['modelName']='Basic Multiple Regression'\n",
        "        self.metrics['trainScore']=tScore\n",
        "        self.metrics['testScore']=vScore\n",
        "        self.metrics['RMSE']=rmse\n",
        "        self.metrics['MSE']=round(mse,2)\n",
        "        self.metrics['className']='MultipleRegression'\n",
        "        #self.checkSignificance()\n",
        "        modelList.append(self.metrics)\n",
        "        print(\".........................Coefficients are....................\")\n",
        "        \n",
        "    def getModel(self):\n",
        "        return self.multiplereg\n",
        "    def getMetrics(self):\n",
        "        return self.metrics\n",
        "    \n",
        "    def checkSignificance(self):\n",
        "        x = sm.add_constant(X_train)\n",
        "        lm = sm.OLS(Y_train,x).fit()\n",
        "        print(lm.summary())\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gew8qYY8p8wj"
      },
      "source": [
        "#container to fit the Lasso Regression  Model\n",
        "class LassoRegression():\n",
        "    def __init__(self):\n",
        "        self.metrics={}\n",
        "        self.lassoreg=LassoCV(alphas = None,cv =10, max_iter = 10000)\n",
        "    def createLassoReg(self):\n",
        "        print(\"Hyper Parameter Tuning for choosing the optimal value of alpha\")\n",
        "        self.lassoreg = LassoCV(alphas = None,cv =10, max_iter = 10000)\n",
        "        self.lassoreg.fit(X_train,Y_train)\n",
        "        alpha = self.lassoreg.alpha_\n",
        "        print(\"Alpha after fitting LassoCV\",alpha)\n",
        "        self.lassoreg = Lasso(alpha)\n",
        "        self.lassoreg.fit(X_train,Y_train)\n",
        "        tScore=self.lassoreg.score(X_train,Y_train)\n",
        "        vScore=self.lassoreg.score(X_valid,Y_valid)\n",
        "        pred=self.lassoreg.predict(X_valid) #predicting values of y for all the xtest rows\n",
        "        mse=mean_squared_error(Y_valid,pred)\n",
        "        rmse=round(mse**0.5,2)\n",
        "        print(\"Training data Score  of LassoCV is\",tScore)\n",
        "        print(\"Validation data Score of LassoCV is\",vScore)\n",
        "        print(\"RMSE in case of Lasso regression Model:\",rmse)\n",
        "        print(\"MSE in case of Lasso regression Model:\",round(mse,2))\n",
        "        \n",
        "        self.metrics['modelName']='Lasso Regression Model'\n",
        "        self.metrics['className']='LassoRegression'\n",
        "        self.metrics['trainScore']=tScore\n",
        "        self.metrics['testScore']=vScore\n",
        "        self.metrics['RMSE']=rmse\n",
        "        self.metrics['MSE']=round(mse,2)\n",
        "        modelList.append(self.metrics)\n",
        "        \n",
        "    def getModel(self):\n",
        "        return self.lassoreg\n",
        "    \n",
        "    def getMetrics(self):\n",
        "        return self.metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BigsMxOOxJG0"
      },
      "source": [
        "#container to fit the Regressor Model\n",
        "class RegressorTree:\n",
        "    def __init__(self):\n",
        "        self.metrics={}\n",
        "        self.regressorTree=DecisionTreeRegressor(random_state = 2) \n",
        "    def createRegressorTree(self):\n",
        "        self.regressorTree.fit(X_train, Y_train)\n",
        "        print(\"Pruning the Tree starts\") \n",
        "        #best_params=self.grid_search(self.regressorTree)\n",
        "        best_params={'max_depth': 9, 'min_samples_leaf': 10}\n",
        "        print(\"Optimal hyperparameters after GridSearchCV\",best_params)\n",
        "        print(\"Pruning ends\")\n",
        "        self.regressorTree = DecisionTreeRegressor(max_depth=best_params['max_depth'],\n",
        "                                              min_samples_leaf =best_params['min_samples_leaf'])\n",
        "        self.regressorTree.fit(X_train,Y_train)\n",
        "        tScore = self.regressorTree.score(X_train, Y_train)\n",
        "        vScore = self.regressorTree.score(X_train, Y_train)\n",
        "        Y_pred = self.regressorTree.predict(X_valid) \n",
        "        # The mean squared error\n",
        "        mse=mean_squared_error(Y_valid,Y_pred)\n",
        "        rmse=round(mse**0.5,2)\n",
        "        print(\"Training data Score  of Regression Tree  Model is\",tScore)\n",
        "        print(\"Validation data Score of Regression Tree   Model is\",vScore)\n",
        "        print(\"RMSE in case of Regression Tree  Model:\",rmse)\n",
        "        print(\"RMSE in case of Regression Tree  Model:\",round(mse,2))\n",
        "        self.metrics['modelName']='Regression Tree Model'\n",
        "        self.metrics['className']='RegressorTree'\n",
        "        self.metrics['trainScore']=tScore\n",
        "        self.metrics['testScore']=vScore\n",
        "        self.metrics['RMSE']=rmse\n",
        "        self.metrics['MSE']=round(mse,2)\n",
        "        modelList.append(self.metrics)\n",
        "        #plot the tree\n",
        "        #self.plotTree()\n",
        "        #plot featureImportance\n",
        "        self.plotfeatureImp()\n",
        "        \n",
        "    def grid_search(self):\n",
        "        #Grid Search for following params to improve accuracy and reduce overfitting\n",
        "        grid_param = {\n",
        "            'max_depth' : range(3,10,1),\n",
        "            'min_samples_leaf' : range(10,40,2)}\n",
        "        grid_search = GridSearchCV(estimator=self.regressorTree,\n",
        "                         param_grid=grid_param,verbose=2,\n",
        "                         cv=10)\n",
        "        grid_search.fit(X_train,Y_train)\n",
        "        best_params=grid_search.best_params_\n",
        "        return best_params\n",
        "    \n",
        "    def plotfeatureImp(self):\n",
        "        #plot the featureImporatnce of each predictor sorted by the largest importance value\n",
        "        feature_cols = X_train.columns\n",
        "        feat_importance = self.regressorTree.tree_.compute_feature_importances(normalize=False)\n",
        "        feat_imp_dict = dict(zip(feature_cols,self.regressorTree.feature_importances_))\n",
        "        feat_imp = pd.DataFrame.from_dict(feat_imp_dict, orient='index')\n",
        "        newdf=feat_imp.sort_values(by=0, ascending=False)\n",
        "        print(\"Feature Importance as per the Regression Tree\")\n",
        "        print(newdf.head(15))        \n",
        "        \n",
        "    def plotTree(self):\n",
        "        dot_data = export_graphviz(self.regressorTree,feature_names = list(X_train.columns),rounded = True,filled = True)\n",
        "        graph = pydotplus.graph_from_dot_data(dot_data)  \n",
        "        Image(graph.create_png())\n",
        "        \n",
        "    def getModel(self):\n",
        "        return self.regressorTree\n",
        "    \n",
        "    def getMetrics(self):\n",
        "        return self.metrics\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGlf2GMd3SAk"
      },
      "source": [
        "#Container to fit RandomForest Regression\n",
        "class RandomForestReg():\n",
        "    def __init__(self):\n",
        "        self.metrics={}\n",
        "        self.rfregressor=RandomForestRegressor()\n",
        "    def createRFForest(self):\n",
        "        print(\"Hyper Parameter Tuning for choosing the optimal value of alpha\")\n",
        "        #self.rfregressor=\n",
        "        self.rfregressor.fit(X_train,Y_train)\n",
        "        #best_params=self.grid_searchforRF()\n",
        "        best_params = {\n",
        "          \"n_estimators\" : 100,\n",
        "          'min_samples_leaf' : 30,\n",
        "          'min_samples_split': 70\n",
        "           }\n",
        "        print(\"optimal params for RF\",best_params)\n",
        "        print(\"HyperParameter tuning for RF ends\")\n",
        "        self.rfregressor = RandomForestRegressor(min_samples_leaf = best_params['min_samples_leaf']\n",
        "                                     ,min_samples_split= best_params['min_samples_split'],\n",
        "                                     n_estimators =best_params['n_estimators'])\n",
        "        self.rfregressor.fit(X_train,Y_train)\n",
        "        tScore=self.rfregressor.score(X_train,Y_train)\n",
        "        vScore=self.rfregressor.score(X_valid,Y_valid)\n",
        "        pred=self.rfregressor.predict(X_valid) #predicting values of y for all the xtest rows\n",
        "        mse=mean_squared_error(Y_valid,pred)\n",
        "        rmse=round(mse**0.5,2)\n",
        "        print(\"Training data Score  of RF regressor is\",tScore)\n",
        "        print(\"Validation data Score of RF regressor is\",vScore)\n",
        "        print(\"RMSE in case of RF Regression Model:\",rmse)\n",
        "        print(\"MSE in case of RF Regression Model:\",round(mse,2))\n",
        "        \n",
        "        self.metrics['modelName']='Random Forest Regression Model'\n",
        "        self.metrics['className']='RandomForestRegressor'\n",
        "        self.metrics['trainScore']=tScore\n",
        "        self.metrics['testScore']=vScore\n",
        "        self.metrics['RMSE']=rmse\n",
        "        self.metrics['MSE']=round(mse,2)\n",
        "        modelList.append(self.metrics)\n",
        "        \n",
        "    def getModel(self):\n",
        "        return self.rfregressor\n",
        "    \n",
        "    def getMetrics(self):\n",
        "        return self.metrics\n",
        "    \n",
        "    \n",
        "    def grid_searchforRF(self):\n",
        "        #Grid search for following params to reduce the model overfitting\n",
        "        grid_param = {\n",
        "          \"n_estimators\" : [90,100,115],\n",
        "          'min_samples_leaf' : [10,20,30,40,50],\n",
        "          'min_samples_split': [40,50,60,70,80]\n",
        "           }\n",
        "        grid_search = GridSearchCV(estimator=self.rfregressor,param_grid=grid_param,cv=5,verbose = 2)\n",
        "        grid_search.fit(X_train,Y_train)\n",
        "        best_params = grid_search.best_params_\n",
        "        return best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_X1KMQnP3uj"
      },
      "source": [
        "#Container to store accuracy metrics of all the Models for all the three clusters\n",
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.cluster0=None\n",
        "        self.cluster1=None\n",
        "        self.cluster2=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkz-vp5Upt78"
      },
      "source": [
        "\n",
        "#Function to find the optimal model having least RMSE values\n",
        "metricsList=[]\n",
        "def findbestModel(clusterNo,model,multipleReg,treeReg,rfReg,lassoReg):\n",
        "    print(\" Finding best Model\")\n",
        "   \n",
        "    sortedList = sorted(modelList, key=lambda item: item.get(\"RMSE\"))[0]\n",
        "    className=sortedList.get('className')\n",
        "    fileName=\"model_cluster\"+str(clusterNo)+\".sav\"\n",
        "    if clusterNo==0:\n",
        "        model.cluster0=pd.DataFrame(modelList)\n",
        "    elif clusterNo ==1:\n",
        "        model.cluster1=pd.DataFrame(modelList)\n",
        "    else:\n",
        "        model.cluster2=pd.DataFrame(modelList)\n",
        "\n",
        "    if className==\"MultipleRegression\":\n",
        "        pickle.dump(multipleReg.getModel(), open(fileName, 'wb'))\n",
        "    elif className ==\"RegressorTree\":\n",
        "        pickle.dump(treeReg.getModel(), open(fileName, 'wb'))\n",
        "    elif className ==\"RandomForestRegressor\":\n",
        "        pickle.dump(rfReg.getModel(), open(fileName, 'wb'))\n",
        "    else:\n",
        "        pickle.dump(lassoReg.getModel(), open(fileName, 'wb'))\n",
        "        \n",
        "        \n",
        "    print(\"Best Model for cluster - \"+str(clusterNo) +\" is\",className)\n",
        "    \n",
        "\n",
        "#Train all the Models one by one \n",
        "def createModels(clusterNo,model):\n",
        "    treeReg=RegressorTree()\n",
        "    lassoReg=LassoRegression()\n",
        "    multipleReg=MultipleRegression()\n",
        "    rfReg=RandomForestReg()\n",
        "    space=' '\n",
        "    print(\"...........................Multiple Regression Model started.......................\")\n",
        "    multipleReg.createRegModel()\n",
        "    print(\"...........................Multiple Regression Model ended.......................\")\n",
        "    print(space*25)\n",
        "    print(space*25)\n",
        "    print(\"...........................Regression  Tree Model start .......................\")\n",
        "    treeReg.createRegressorTree()\n",
        "    print(\"...........................Regression  Tree Model end .......................\")\n",
        "    print(space*25)\n",
        "    print(space*25)\n",
        "    print(\"...........................Random Forest Model start .......................\")\n",
        "    rfReg.createRFForest()\n",
        "    print(\"...........................Random Forest Model end.......................\")\n",
        "    print(space*25)\n",
        "    print(space*25)\n",
        "    print(\"...........................Lasso Regression Model start .......................\")\n",
        "    lassoReg.createLassoReg()\n",
        "    print(\"...........................Lasso Regression Model start .......................\")\n",
        "    findbestModel(clusterNo,model,multipleReg,treeReg,rfReg,lassoReg)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNt-2mqS5Jzf"
      },
      "source": [
        "### Train model for each cluster "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrZXGG5KXkUB",
        "outputId": "74ff6402-74e1-47da-9085-a058e3b18f28"
      },
      "source": [
        "model=Model()\n",
        "for  clusterNo in range(0,3):\n",
        "    modelList=[]\n",
        "    df=pd.read_csv(\"Cluster_\"+str(clusterNo)+\".csv\",index_col=0)\n",
        "    use_sample = False\n",
        "    sample_fraction = 0.01\n",
        "    if use_sample:\n",
        "        df = df.sample(frac=sample_fraction).copy()\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    Y=df['Purchase']\n",
        "    X=df.drop(['Purchase','clusterNo'],axis=1)\n",
        "    #Create dummy columns\n",
        "    for col in ['Gender','Marital_Status','City_Category','Occupation','Product_Category_1']:\n",
        "    X=pd.get_dummies(X, columns=[col], prefix=[col], drop_first=True)\n",
        "    print(\"Shape of X is \",X.shape)\n",
        "    # Divide into train and valid dataset \n",
        "    X_train,X_valid = train_test_split(X, test_size=0.2, random_state=42, shuffle=True)\n",
        "    Y_train,Y_valid = train_test_split(Y, test_size=0.2, random_state=42, shuffle=True)\n",
        "    createModels(clusterNo,model)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X is  (94750, 45)\n",
            "...........................Multiple Regression Model started.......................\n",
            "Training data Score is 0.6833937410364411\n",
            "Validation data Score is 0.6828909235916903\n",
            "RMSE in case of Multiple regression Model: 2748.72\n",
            "MSE in case of Multiple regression Model: 7555476.691163134\n",
            ".........................Coefficients are....................\n",
            "...........................Multiple Regression Model ended.......................\n",
            "                         \n",
            "                         \n",
            "...........................Regression  Tree Model start .......................\n",
            "Pruning the Tree starts\n",
            "Optimal hyperparameters after GridSearchCV {'max_depth': 9, 'min_samples_leaf': 10}\n",
            "Pruning ends\n",
            "Training data Score  of Regression Tree  Model is 0.6446103776183943\n",
            "Validation data Score of Regression Tree   Model is 0.6446103776183943\n",
            "RMSE in case of Regression Tree  Model: 2922.53\n",
            "RMSE in case of Regression Tree  Model: 8541187.61\n",
            "Feature Importance as per the Regression Tree\n",
            "                                   0\n",
            "Product_Category_1_5        0.182564\n",
            "Product_Category_1_8        0.162011\n",
            "Product_Category_1_11       0.123419\n",
            "Product_Category_1_4        0.120826\n",
            "Product_Category_1_13       0.117877\n",
            "Product_Category_1_12       0.107771\n",
            "Product_Category_1_18       0.066106\n",
            "Product_Category_1_20       0.065904\n",
            "Product_Category_1_19       0.045993\n",
            "Stay_In_Current_City_Years  0.001469\n",
            "Age                         0.001185\n",
            "Gender_M                    0.000725\n",
            "City_Category_C             0.000649\n",
            "City_Category_B             0.000593\n",
            "Occupation_16               0.000378\n",
            "...........................Regression  Tree Model end .......................\n",
            "                         \n",
            "                         \n",
            "...........................Random Forest Model start .......................\n",
            "Hyper Parameter Tuning for choosing the optimal value of alpha\n",
            "optimal params for RF {'n_estimators': 100, 'min_samples_leaf': 30, 'min_samples_split': 70}\n",
            "HyperParameter tuning for RF ends\n",
            "Training data Score  of RF regressor is 0.7115802793018389\n",
            "Validation data Score of RF regressor is 0.7029137232492597\n",
            "RMSE in case of RF Regression Model: 2660.53\n",
            "MSE in case of RF Regression Model: 7078411.2\n",
            "...........................Random Forest Model end.......................\n",
            "                         \n",
            "                         \n",
            "...........................Lasso Regression Model start .......................\n",
            "Hyper Parameter Tuning for choosing the optimal value of alpha\n",
            "Alpha after fitting LassoCV 0.7403845539020891\n",
            "Training data Score  of LassoCV is 0.6832650951579828\n",
            "Validation data Score of LassoCV is 0.6826802219750957\n",
            "RMSE in case of Lasso regression Model: 2749.64\n",
            "MSE in case of Lasso regression Model: 7560496.89\n",
            "...........................Lasso Regression Model start .......................\n",
            " Finding best Model\n",
            "Best Model for cluster - 0 is RandomForestRegressor\n",
            "Shape of X is  (161379, 45)\n",
            "...........................Multiple Regression Model started.......................\n",
            "Training data Score is 0.6278519663214202\n",
            "Validation data Score is 0.6229351766857743\n",
            "RMSE in case of Multiple regression Model: 3038.85\n",
            "MSE in case of Multiple regression Model: 9234637.766519817\n",
            ".........................Coefficients are....................\n",
            "...........................Multiple Regression Model ended.......................\n",
            "                         \n",
            "                         \n",
            "...........................Regression  Tree Model start .......................\n",
            "Pruning the Tree starts\n",
            "Optimal hyperparameters after GridSearchCV {'max_depth': 9, 'min_samples_leaf': 10}\n",
            "Pruning ends\n",
            "Training data Score  of Regression Tree  Model is 0.5864335047792355\n",
            "Validation data Score of Regression Tree   Model is 0.5864335047792355\n",
            "RMSE in case of Regression Tree  Model: 3217.61\n",
            "RMSE in case of Regression Tree  Model: 10353018.31\n",
            "Feature Importance as per the Regression Tree\n",
            "                                   0\n",
            "Product_Category_1_5        0.236837\n",
            "Product_Category_1_11       0.165141\n",
            "Product_Category_1_8        0.161850\n",
            "Product_Category_1_4        0.156182\n",
            "Product_Category_1_13       0.097671\n",
            "Product_Category_1_12       0.060525\n",
            "Product_Category_1_20       0.046137\n",
            "Product_Category_1_18       0.035571\n",
            "Product_Category_1_19       0.034494\n",
            "City_Category_C             0.001003\n",
            "Age                         0.000915\n",
            "Stay_In_Current_City_Years  0.000721\n",
            "Marital_Status_1            0.000466\n",
            "Gender_M                    0.000349\n",
            "Occupation_20               0.000257\n",
            "...........................Regression  Tree Model end .......................\n",
            "                         \n",
            "                         \n",
            "...........................Random Forest Model start .......................\n",
            "Hyper Parameter Tuning for choosing the optimal value of alpha\n",
            "optimal params for RF {'n_estimators': 100, 'min_samples_leaf': 30, 'min_samples_split': 70}\n",
            "HyperParameter tuning for RF ends\n",
            "Training data Score  of RF regressor is 0.6543128181977533\n",
            "Validation data Score of RF regressor is 0.6423081272735056\n",
            "RMSE in case of RF Regression Model: 2959.76\n",
            "MSE in case of RF Regression Model: 8760177.75\n",
            "...........................Random Forest Model end.......................\n",
            "                         \n",
            "                         \n",
            "...........................Lasso Regression Model start .......................\n",
            "Hyper Parameter Tuning for choosing the optimal value of alpha\n",
            "Alpha after fitting LassoCV 0.8221406539384079\n",
            "Training data Score  of LassoCV is 0.6276958656888156\n",
            "Validation data Score of LassoCV is 0.6227028846491939\n",
            "RMSE in case of Lasso regression Model: 3039.79\n",
            "MSE in case of Lasso regression Model: 9240326.8\n",
            "...........................Lasso Regression Model start .......................\n",
            " Finding best Model\n",
            "Best Model for cluster - 1 is RandomForestRegressor\n",
            "Shape of X is  (291262, 45)\n",
            "...........................Multiple Regression Model started.......................\n",
            "Training data Score is 0.6197089890015279\n",
            "Validation data Score is 0.6211239521075794\n",
            "RMSE in case of Multiple regression Model: 3045.14\n",
            "MSE in case of Multiple regression Model: 9272882.961893653\n",
            ".........................Coefficients are....................\n",
            "...........................Multiple Regression Model ended.......................\n",
            "                         \n",
            "                         \n",
            "...........................Regression  Tree Model start .......................\n",
            "Pruning the Tree starts\n",
            "Optimal hyperparameters after GridSearchCV {'max_depth': 9, 'min_samples_leaf': 10}\n",
            "Pruning ends\n",
            "Training data Score  of Regression Tree  Model is 0.5769303172179172\n",
            "Validation data Score of Regression Tree   Model is 0.5769303172179172\n",
            "RMSE in case of Regression Tree  Model: 3214.46\n",
            "RMSE in case of Regression Tree  Model: 10332728.35\n",
            "Feature Importance as per the Regression Tree\n",
            "                                   0\n",
            "Product_Category_1_5        0.244329\n",
            "Product_Category_1_8        0.162853\n",
            "Product_Category_1_11       0.160292\n",
            "Product_Category_1_4        0.153778\n",
            "Product_Category_1_13       0.095170\n",
            "Product_Category_1_12       0.055538\n",
            "Product_Category_1_20       0.052491\n",
            "Product_Category_1_18       0.036614\n",
            "Product_Category_1_19       0.034951\n",
            "Age                         0.000648\n",
            "Stay_In_Current_City_Years  0.000590\n",
            "City_Category_C             0.000517\n",
            "Marital_Status_1            0.000337\n",
            "City_Category_B             0.000319\n",
            "Gender_M                    0.000318\n",
            "...........................Regression  Tree Model end .......................\n",
            "                         \n",
            "                         \n",
            "...........................Random Forest Model start .......................\n",
            "Hyper Parameter Tuning for choosing the optimal value of alpha\n",
            "optimal params for RF {'n_estimators': 100, 'min_samples_leaf': 30, 'min_samples_split': 70}\n",
            "HyperParameter tuning for RF ends\n",
            "Training data Score  of RF regressor is 0.6465038082635974\n",
            "Validation data Score of RF regressor is 0.6403725775918944\n",
            "RMSE in case of RF Regression Model: 2966.78\n",
            "MSE in case of RF Regression Model: 8801778.36\n",
            "...........................Random Forest Model end.......................\n",
            "                         \n",
            "                         \n",
            "...........................Lasso Regression Model start .......................\n",
            "Hyper Parameter Tuning for choosing the optimal value of alpha\n",
            "Alpha after fitting LassoCV 0.8335218003221311\n",
            "Training data Score  of LassoCV is 0.6195469530461344\n",
            "Validation data Score of LassoCV is 0.6209232223380539\n",
            "RMSE in case of Lasso regression Model: 3045.95\n",
            "MSE in case of Lasso regression Model: 9277795.77\n",
            "...........................Lasso Regression Model start .......................\n",
            " Finding best Model\n",
            "Best Model for cluster - 2 is RandomForestRegressor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omm7yzxdjbAK"
      },
      "source": [
        "#### Create Multi Layer perceptron Model having 2 hidden layers and RELU as the activation function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfc9bfPgkVcM"
      },
      "source": [
        "#Define the Neural Network Architecture\n",
        "class MLP(nn.Module):\n",
        "  '''\n",
        "    Multilayer Perceptron for regression.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(45, 20),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(20, 15),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(15, 1)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "      Forward pass\n",
        "    '''\n",
        "    return self.layers(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWZAvbdDwUiC"
      },
      "source": [
        "\n",
        "#Function to train the Neural Network for n epochs with back propagation \n",
        "def train(model, train_loader, optimizer, epoch,loss_function):\n",
        "    #model.train(); # It is specially required when Dropout and Batch Normalization is implemented.\n",
        "    total_loss=0\n",
        "    # Iterate through dataset\n",
        "    for data, target in train_loader:\n",
        "        target = target.unsqueeze(1)\n",
        "        \n",
        "        # Zero grad\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = (loss_function(output, target))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print average loss\n",
        "    avgloss_epoch=total_loss / len(train_loader.dataset)\n",
        "    if(epoch%2==0):\n",
        "      print(\"Train Epoch: {}\\t Loss: {:.6f}\".format(epoch, avgloss_epoch))\n",
        "    return avgloss_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGzZC1kOwUqk"
      },
      "source": [
        "#Function to test the Neural Network  performance on validation data\n",
        "def test(model, test_loader,epoch,loss_function):\n",
        "    model.eval() #It is specially required when Dropout and Batch Normalization is implemented.\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            target = target.unsqueeze(1)\n",
        "            \n",
        "            output = model(data)\n",
        "            test_loss +=(loss_function(output, target)).item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    if(epoch%2==0):\n",
        "      print('\\nTest set: Average loss: {:.4f}\\n'.format(\n",
        "        test_loss))\n",
        "    return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUDLU1-c6mhK"
      },
      "source": [
        "### plot the loss value sof Training and Validation data for each epoch\n",
        "def plotLoss(training_loss,validation_loss,epochs):\n",
        "  plt.figure()\n",
        "  plt.plot(range(1,epochs),training_loss,color='b',label=\"Training\")\n",
        "  plt.plot(range(1,epochs),validation_loss,color='g',label=\"Validation\")\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qbXm9plZTar"
      },
      "source": [
        "#Convert Numpyarrays to Tensor and then use DataLoader to create different batches of training and validation data.\n",
        "def preprocess(df,clusterNo,requireLoader):\n",
        "    Y=df['Purchase']\n",
        "    X=df.drop(['Purchase','clusterNo'],axis=1)\n",
        "    for col in ['Gender','Marital_Status','City_Category','Occupation','Product_Category_1']:\n",
        "        X=pd.get_dummies(X, columns=[col], prefix=[col], drop_first=True)\n",
        "    # Divide into train and valid dataset \n",
        "    X_train, X_valid = train_test_split(X.values, test_size=0.2, random_state=42, shuffle=True)\n",
        "    Y_train, Y_valid = train_test_split(Y.values, test_size=0.2, random_state=42, shuffle=True)\n",
        "    X_train=torch.FloatTensor(X_train)\n",
        "    X_valid=torch.FloatTensor(X_valid)\n",
        "    Y_train=torch.FloatTensor(Y_train)\n",
        "    Y_valid=torch.FloatTensor(Y_valid)\n",
        "    train_data = TensorDataset(X_train,Y_train)\n",
        "    valid_data = TensorDataset(X_valid,Y_valid)\n",
        "    batch_size=32\n",
        "    if requireLoader :\n",
        "      train_loader = DataLoader(dataset=train_data,batch_size=batch_size, shuffle=False, drop_last=True)      \n",
        "      validation_loader = DataLoader(dataset=valid_data, batch_size=batch_size, shuffle=False, drop_last=True)  \n",
        "      print(\"NO. of batches in Training datset  for cluster \",clusterNo, \"is :\",len(train_loader))\n",
        "      print(\"NO. of batches in Validation datset for cluster \",clusterNo,\"is :\",len(validation_loader))\n",
        "      return train_loader,validation_loader\n",
        "    else:\n",
        "      return X_valid,Y_valid\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijHP1czVsuKp"
      },
      "source": [
        "#Define Loss and optimization technique for Neural Netwk,train model for n epochs\n",
        "def trainANN(train_loader,validation_loader,epochs,clusterNo,model):\n",
        "    torch.manual_seed(20)\n",
        "    model_MLP=MLP()\n",
        "    print(model_MLP.parameters)\n",
        "    ###Backward Propogation-- Define the loss_function,define the opti\n",
        "    loss_function=nn.MSELoss()\n",
        "    optimizer=torch.optim.Adam(model_MLP.parameters(),lr=0.01)\n",
        "    training_loss=[]\n",
        "    validation_loss=[]\n",
        "    for epoch in range(1,epochs):\n",
        "        avgtrain_loss=train(model_MLP, train_loader, optimizer, epoch,loss_function)\n",
        "        training_loss.append(avgtrain_loss)\n",
        "        avgtest_loss=test(model_MLP, validation_loader,epoch,loss_function)\n",
        "        validation_loss.append(avgtest_loss)\n",
        "    #Save the model\n",
        "    name=\"MLP_cluster\"+str(clusterNo)+\".pt\"\n",
        "    torch.save(model_MLP,name)\n",
        "    tempDict=[{'modelName':'Multi Layer Perceptron','trainScore':'NA'\t,'testScore':'NA',\t\n",
        "            'RMSE':'NA','MSE':avgtest_loss,'className':'MLP'}]\n",
        "    tempdf=pd.DataFrame.from_dict(tempDict)\n",
        "    if clusterNo==0:\n",
        "        model.cluster0=pd.concat([model.cluster0,tempdf],ignore_index=True)\n",
        "    elif clusterNo==1:\n",
        "        model.cluster1=pd.concat([model.cluster1,tempdf],ignore_index=True)\n",
        "    else:\n",
        "        model.cluster2=pd.concat([model.cluster2,tempdf],ignore_index=True)\n",
        "        \n",
        "    return training_loss,validation_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KGyrr7lnk2UQ",
        "outputId": "1926fe63-7b48-44b3-8c6a-2fb84b82a0eb"
      },
      "source": [
        "#Train Model for each cluster by calling above defined functions\n",
        "epochs=10\n",
        "space=' '\n",
        "for  clusterNo in range(0,3):\n",
        "    avgtrain_loss=[];avgvalidation_loss=[]\n",
        "    df=pd.read_csv(\"Cluster_\"+str(clusterNo)+\".csv\",index_col=0)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print(\".......................Preprocessing for cluster\",clusterNo,\"starts here................................\")\n",
        "    train_loader,validation_loader=preprocess(df,clusterNo,True)\n",
        "    print(\".......................Preprocessing for cluster\",clusterNo,\"ends here................................\")\n",
        "    print(\".......................Training for cluster\",clusterNo,\"starts here................................\")\n",
        "   \n",
        "    avgtrain_loss,avgvalidation_loss=trainANN(train_loader,validation_loader,epochs,clusterNo,model)\n",
        "    print(\".......................Training for cluster\",clusterNo,\"ends here................................\")\n",
        "    print(space*25)\n",
        "    print(\"...............................Training Loss vs Validation Loss for cluster......................\" ,clusterNo)\n",
        "    plotLoss(avgtrain_loss,avgvalidation_loss,epochs)\n",
        "   \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".......................Preprocessing for cluster 0 starts here................................\n",
            "\n",
            "NO. of batches in Training datset  for cluster  0 is : 2368\n",
            "NO. of batches in Validation datset for cluster  0 is : 592\n",
            ".......................Preprocessing for cluster 0 ends here................................\n",
            ".......................Training for cluster 0 starts here................................\n",
            "<bound method Module.parameters of MLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=45, out_features=20, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=20, out_features=15, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=15, out_features=1, bias=True)\n",
            "  )\n",
            ")>\n",
            "Train Epoch: 2\t Loss: 256036.011656\n",
            "\n",
            "Test set: Average loss: 243078.8179\n",
            "\n",
            "Train Epoch: 4\t Loss: 241351.015765\n",
            "\n",
            "Test set: Average loss: 237307.0780\n",
            "\n",
            "Train Epoch: 6\t Loss: 240829.480343\n",
            "\n",
            "Test set: Average loss: 237117.9715\n",
            "\n",
            "Train Epoch: 8\t Loss: 240761.699354\n",
            "\n",
            "Test set: Average loss: 237055.7031\n",
            "\n",
            ".......................Training for cluster 0 ends here................................\n",
            "                         \n",
            "...............................Training Loss vs Validation Loss for cluster...................... 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".......................Preprocessing for cluster 1 starts here................................\n",
            "\n",
            "NO. of batches in Training datset  for cluster  1 is : 4034\n",
            "NO. of batches in Validation datset for cluster  1 is : 1008\n",
            ".......................Preprocessing for cluster 1 ends here................................\n",
            ".......................Training for cluster 1 starts here................................\n",
            "<bound method Module.parameters of MLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=45, out_features=20, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=20, out_features=15, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=15, out_features=1, bias=True)\n",
            "  )\n",
            ")>\n",
            "Train Epoch: 2\t Loss: 288085.564114\n",
            "\n",
            "Test set: Average loss: 288748.8662\n",
            "\n",
            "Train Epoch: 4\t Loss: 285338.668947\n",
            "\n",
            "Test set: Average loss: 288207.3140\n",
            "\n",
            "Train Epoch: 6\t Loss: 285049.396538\n",
            "\n",
            "Test set: Average loss: 287937.6193\n",
            "\n",
            "Train Epoch: 8\t Loss: 284906.073825\n",
            "\n",
            "Test set: Average loss: 287848.6956\n",
            "\n",
            ".......................Training for cluster 1 ends here................................\n",
            "                         \n",
            "...............................Training Loss vs Validation Loss for cluster...................... 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".......................Preprocessing for cluster 2 starts here................................\n",
            "\n",
            "NO. of batches in Training datset  for cluster  2 is : 7281\n",
            "NO. of batches in Validation datset for cluster  2 is : 1820\n",
            ".......................Preprocessing for cluster 2 ends here................................\n",
            ".......................Training for cluster 2 starts here................................\n",
            "<bound method Module.parameters of MLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=45, out_features=20, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=20, out_features=15, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=15, out_features=1, bias=True)\n",
            "  )\n",
            ")>\n",
            "Train Epoch: 2\t Loss: 292801.692349\n",
            "\n",
            "Test set: Average loss: 290504.2430\n",
            "\n",
            "Train Epoch: 4\t Loss: 292620.125066\n",
            "\n",
            "Test set: Average loss: 290276.3691\n",
            "\n",
            "Train Epoch: 6\t Loss: 292524.142252\n",
            "\n",
            "Test set: Average loss: 290143.9566\n",
            "\n",
            "Train Epoch: 8\t Loss: 292448.252212\n",
            "\n",
            "Test set: Average loss: 290060.4026\n",
            "\n",
            ".......................Training for cluster 2 ends here................................\n",
            "                         \n",
            "...............................Training Loss vs Validation Loss for cluster...................... 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1GR5tyj5Jzl"
      },
      "source": [
        "#### Accuracy Metrics of all the Models for each Cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "0SSJ2XoShP8x",
        "outputId": "eceb6548-90e6-4f5c-9cdd-c24b1693748a"
      },
      "source": [
        "#Accuracy metrics of models developed for Cluster 0\n",
        "model.cluster0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modelName</th>\n",
              "      <th>trainScore</th>\n",
              "      <th>testScore</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>className</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Basic Multiple Regression</td>\n",
              "      <td>0.683394</td>\n",
              "      <td>0.682891</td>\n",
              "      <td>2748.72</td>\n",
              "      <td>7.555477e+06</td>\n",
              "      <td>MultipleRegression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regression Tree Model</td>\n",
              "      <td>0.64461</td>\n",
              "      <td>0.64461</td>\n",
              "      <td>2922.53</td>\n",
              "      <td>8.541188e+06</td>\n",
              "      <td>RegressorTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest Regression Model</td>\n",
              "      <td>0.71158</td>\n",
              "      <td>0.702914</td>\n",
              "      <td>2660.53</td>\n",
              "      <td>7.078411e+06</td>\n",
              "      <td>RandomForestRegressor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lasso Regression Model</td>\n",
              "      <td>0.683265</td>\n",
              "      <td>0.68268</td>\n",
              "      <td>2749.64</td>\n",
              "      <td>7.560497e+06</td>\n",
              "      <td>LassoRegression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Multi Layer Perceptron</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "      <td>2.370277e+05</td>\n",
              "      <td>MLP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        modelName  ...              className\n",
              "0       Basic Multiple Regression  ...     MultipleRegression\n",
              "1           Regression Tree Model  ...          RegressorTree\n",
              "2  Random Forest Regression Model  ...  RandomForestRegressor\n",
              "3          Lasso Regression Model  ...        LassoRegression\n",
              "4          Multi Layer Perceptron  ...                    MLP\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "ZKWvmVVAzVoq",
        "outputId": "67cac335-4461-4158-ae39-051b94f5e2ff"
      },
      "source": [
        "#Accuracy metrics of models developed for Cluster 1\n",
        "model.cluster1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modelName</th>\n",
              "      <th>trainScore</th>\n",
              "      <th>testScore</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>className</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Basic Multiple Regression</td>\n",
              "      <td>0.627852</td>\n",
              "      <td>0.622935</td>\n",
              "      <td>3038.85</td>\n",
              "      <td>9.234638e+06</td>\n",
              "      <td>MultipleRegression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regression Tree Model</td>\n",
              "      <td>0.586434</td>\n",
              "      <td>0.586434</td>\n",
              "      <td>3217.61</td>\n",
              "      <td>1.035302e+07</td>\n",
              "      <td>RegressorTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest Regression Model</td>\n",
              "      <td>0.654313</td>\n",
              "      <td>0.642308</td>\n",
              "      <td>2959.76</td>\n",
              "      <td>8.760178e+06</td>\n",
              "      <td>RandomForestRegressor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lasso Regression Model</td>\n",
              "      <td>0.627696</td>\n",
              "      <td>0.622703</td>\n",
              "      <td>3039.79</td>\n",
              "      <td>9.240327e+06</td>\n",
              "      <td>LassoRegression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Multi Layer Perceptron</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "      <td>2.878398e+05</td>\n",
              "      <td>MLP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        modelName  ...              className\n",
              "0       Basic Multiple Regression  ...     MultipleRegression\n",
              "1           Regression Tree Model  ...          RegressorTree\n",
              "2  Random Forest Regression Model  ...  RandomForestRegressor\n",
              "3          Lasso Regression Model  ...        LassoRegression\n",
              "4          Multi Layer Perceptron  ...                    MLP\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "1aA2CyZ0zV1a",
        "outputId": "5bfe0e88-29de-4db5-eaab-288e673095b6"
      },
      "source": [
        "#Accuracy metrics of models developed for Cluster 2\n",
        "model.cluster2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modelName</th>\n",
              "      <th>trainScore</th>\n",
              "      <th>testScore</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>className</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Basic Multiple Regression</td>\n",
              "      <td>0.619709</td>\n",
              "      <td>0.621124</td>\n",
              "      <td>3045.14</td>\n",
              "      <td>9.272883e+06</td>\n",
              "      <td>MultipleRegression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Regression Tree Model</td>\n",
              "      <td>0.57693</td>\n",
              "      <td>0.57693</td>\n",
              "      <td>3214.46</td>\n",
              "      <td>1.033273e+07</td>\n",
              "      <td>RegressorTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest Regression Model</td>\n",
              "      <td>0.646504</td>\n",
              "      <td>0.640373</td>\n",
              "      <td>2966.78</td>\n",
              "      <td>8.801778e+06</td>\n",
              "      <td>RandomForestRegressor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lasso Regression Model</td>\n",
              "      <td>0.619547</td>\n",
              "      <td>0.620923</td>\n",
              "      <td>3045.95</td>\n",
              "      <td>9.277796e+06</td>\n",
              "      <td>LassoRegression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Multi Layer Perceptron</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "      <td>2.900269e+05</td>\n",
              "      <td>MLP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        modelName  ...              className\n",
              "0       Basic Multiple Regression  ...     MultipleRegression\n",
              "1           Regression Tree Model  ...          RegressorTree\n",
              "2  Random Forest Regression Model  ...  RandomForestRegressor\n",
              "3          Lasso Regression Model  ...        LassoRegression\n",
              "4          Multi Layer Perceptron  ...                    MLP\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4V7ubzuCsjO"
      },
      "source": [
        "Define new accuracy function and calculate average accuracy per cluster. For each prediction We will calculate 1-abs(Prediction-Original)/Original to observe how accuractely the model is predicting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D5t5Hzn51Ad"
      },
      "source": [
        "def calculateAccuracy(accuracyList):\n",
        "  for  clusterNo in range(0,3):\n",
        "    df=pd.read_csv(\"Cluster_\"+str(clusterNo)+\".csv\",index_col=0)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print(\".......................Preprocessing for cluster\",clusterNo,\"starts here................................\")\n",
        "    xValid,yValid=preprocess(df,clusterNo,False)\n",
        "    modelName='MLP_cluster'+str(clusterNo)+'.pt'\n",
        "    print(\"modelName is\",modelName)\n",
        "    model=torch.load(modelName)\n",
        "    with torch.no_grad():\n",
        "      predictions=model(xValid)\n",
        "      tempdf=pd.DataFrame(predictions.numpy(),columns=[\"prediction\"])\n",
        "      tempdf['original']=yValid.numpy()\n",
        "      tempdf['accuracy']=round((1- abs(tempdf['prediction']-tempdf['original'])/tempdf['original'])*100,2)\n",
        "      print(\"......................Cluster \"+str(clusterNo) +\" prediction starts here.................\")\n",
        "      print(tempdf.head())\n",
        "      print(\"Average Accuracy for cluster \"+str(clusterNo) +\"is : \" ,round(tempdf['accuracy'].mean(),2) ,\"%\")\n",
        "      accuracyList.append(round(tempdf['accuracy'].mean(),2))\n",
        "      print(\"......................Cluster \"+str(clusterNo) +\" prediction  ends starts here.................\")\n",
        "    \n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_me7wmVH8uN_",
        "outputId": "67b7b016-88ef-4ea8-8ae4-91fa4c1f8a68"
      },
      "source": [
        "accuracyList=[]\n",
        "calculateAccuracy(accuracyList)\n",
        "print(\"\\n\\n Overall Average accuracy across all the three clusters is \" ,round(sum(accuracyList)/len(accuracyList),2),\"%\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".......................Preprocessing for cluster 0 starts here................................\n",
            "modelName is MLP_cluster0.pt\n",
            "......................Cluster 0 prediction starts here.................\n",
            "     prediction  original   accuracy\n",
            "0   7430.804688    8088.0  91.870003\n",
            "1   6503.877441    8575.0  75.849998\n",
            "2  14215.417969   15486.0  91.800003\n",
            "3  14006.206055   12111.0  84.349998\n",
            "4   7652.674805    7902.0  96.839996\n",
            "Average Accuracy for cluster 0is :  67.2 %\n",
            "......................Cluster 0 ends starts here.................\n",
            ".......................Preprocessing for cluster 1 starts here................................\n",
            "modelName is MLP_cluster1.pt\n",
            "......................Cluster 1 prediction starts here.................\n",
            "     prediction  original   accuracy\n",
            "0  13522.276367   19252.0  70.239998\n",
            "1   6637.180176    7132.0  93.059998\n",
            "2  14665.047852   16620.0  88.239998\n",
            "3  14299.765625   19094.0  74.889999\n",
            "4  13496.600586   15198.0  88.809998\n",
            "Average Accuracy for cluster 1is :  64.16 %\n",
            "......................Cluster 1 ends starts here.................\n",
            ".......................Preprocessing for cluster 2 starts here................................\n",
            "modelName is MLP_cluster2.pt\n",
            "......................Cluster 2 prediction starts here.................\n",
            "     prediction  original   accuracy\n",
            "0   6072.600098    8856.0  68.570000\n",
            "1   7386.104492    8043.0  91.830002\n",
            "2   5441.472656    5244.0  96.230003\n",
            "3   2174.348145    2771.0  78.470001\n",
            "4  13116.567383   15447.0  84.910004\n",
            "Average Accuracy for cluster 2is :  64.19 %\n",
            "......................Cluster 2 ends starts here.................\n",
            "\n",
            "\n",
            " Overall Average accuracy across all the three clusters is  65.18 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZLPYCfU5Jzo"
      },
      "source": [
        "####  Deep Neural Network  is performing far better than any other models when we compare the MSE values. Aong ML Models ,Random Forest looks promising in predicting the accurate purchase amount."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuC1VFxCzqaa"
      },
      "source": [
        "#Save the Model and check one of the models to predict the purchase amount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHjaalet1bx2",
        "outputId": "377aaef5-22b2-48bc-aa0d-5474345c5dee"
      },
      "source": [
        "model=torch.load('MLP_cluster2.pt')\n",
        "temp=[5., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
        "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
        "         0., 0., 0., 0.,0.,0.,0.,0.,0.]\n",
        "\n",
        "with torch.no_grad():\n",
        "    print(model(torch.Tensor(temp)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5981.5835])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOBcQW5xATkg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}